\documentclass[a4wide, 11pt]{article}
\usepackage{a4, fullpage}
\newcommand{\tab}{\hspace*{2em}}
\usepackage[margin=2cm]{geometry}
\newcommand{\tx}{\texttt}

\begin{document}

\title{OS211 \\ Task1: Threads \\ Design Document}
\author{Francesco Di Mauro, Thomas Rooney, Alex Rozanski}
\maketitle


\section{Alarm Clock}
\subsection{Data Structures}

Added to enum \texttt{thread\_status}: \\
\tab \tab \texttt{THREAD\_SLEEP} \\ \\
\tab \tab Member of the \texttt{enum thread\_status}, representing a sleeping thread.
\\\\
Added to \texttt{struct\_thread}: \\
\tab\tab \texttt{vlong long wakeup\_tick} \\
\tab\tab If a thread is is sleeping, this the tick it's going to be woken up on.
\\\\
Added to \texttt{thread.c} as a global variable: \\
\tab\tab \texttt{static struct list sleeping\_list} \\
\tab\tab Ordered list of processes currently sleeping.\\ 
\tab\tab Processes in this list 
   have state set to \texttt{THREAD\_SLEEP}. \\
\tab\tab This list is ordered suck that the head
   is the next thread to be woken up.

\subsection{Algorithms}
\subsubsection{A2}
The first operation that the function \texttt{timer\_sleep} carries out is disabling the interrupts, then it calls out to the new method \texttt{thread\_sleep()}. This function calculates the tick the thread needs to be woken up on, sets the status of the thread to \texttt{THREAD\_SLEEP}, then adds it to the sleeping list. Finally, \texttt{thread\_sleep()} will call \texttt{schedule}, in order to choose a different thread to run. When returning from \texttt{thread\_sleep()}, the interrupts will be re-enabled. Putting a thread to sleep should be an atomic operation because it accesses the kernel's thread structure: if an interrupt occurs while writing to the sleeping threads list, this will cause a fatal exception. 

\subsubsection{A3}

The list of sleeping threads is ordered by the \tx{wakeup\_tick} member
which has been added to \tx{struct thread}. This is an absolute tick value that the thread 
should sleep until, which is set when \tx{timer\_sleep()} is invoked. Thanks to this ordering, when we iterate over the sleeping threads in \tx{thread\_sleep\_ticker()} (which is called from the
timer interrupt handler) we can stop iteration as soon as a thread whose
\tx{wakeup\_tick} value is later than the current tick is found.
\\
Furthermore, because the tick which we want the thread to wake up on is stored as
an absolute value rather than a relative number of ticks to sleep for, we don't
need to update any sleep state in the timer interrupt handler for the sleeping
threads.

\emph{Add example with values?}

\subsection{Synchronization}

We chose this design because allows the system to perform a fairly low amount of processing in the
timer interrupt handler. As tx{thread\_sleep\_ticker()} is called every tick, this feature is crucial. Our
initial design used an unordered list of sleeping threads, and each thread
stored the number of ticks to sleep for. In the timer interrupt handler we
would decrement the number of ticks each thread in the sleeping queue was
sleeping for, and then wake up the thread when this count hit zero. This implementation was
really inefficient because at every tick we were not just iterating over every sleeping
thread , but also modifying the state of every thread.

\section{Priority Scheduling}
\subsection{Data Structures}

Added to \tx{struct thread}: \\\\
\tab\tab \tx{struct list lock\_list}:\\
\tab\tab This is an ordered list of the thread's held locks, with highest priority first. \\
\tab\tab They are only added when they have also been donated to.
\\\\
 \tab\tab   \tx{int priority}:\\
 \tab\tab This contains the thread's default, non-donated-to, priority.
\\\\
\tab\tab \tx{struct lock *blocker}:\\
\tab\tab This is a pointer to the lock that is currently blocking it, or NULL \\
\tab\tab should the thread not be currently blocked by a lock.
    \\\\    
Added to \tx{struct lock}:
\\\\
\tab\tab bool \tx{donated\_flag}:\\
\tab\tab This is a flag indicating whether the lock has donated its priority to its holder, or not.
\\\\
\tab\tab \tx{struct list\_elem elem}:\\
\tab\tab This is a \tx{list\_elem} structure such that the lock can be tracked via the pintos list structure -\\
\tab\tab meaning a thread can know which locks it currently holds.
\\\\
Added to \tx{struct semaphore}:
  \\\\  
\tab\tab \tx{int *priority}:\\
\tab\tab This is a pointer to a thread's priority value, this is initially the thread that holds it,\\
\tab\tab but is updated to the greatest priority of the thread's currently in it's wait queue.
\newpage

\subsubsection{B2}
\begin{verbatim}
--------------------------------------------------------------------------------
--------------------------------- ASCII Diagram: -------------------------------
--------------------------------- Initial Setup: -------------------------------
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |    M     |    H     |-
---------|pri:NULL   |pri:NULL   |-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder:NULL|holder:NULL|-----------|locks:[]  |locks:[]  |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:0 |blocker:0 |
--------------------------------------------------------------------------------
-thread_get_priority(L)=1 - thread_get_priority(M)=2 - thread_get_priority(H)=3-
================================================================================
-- Thread L: lock_acquire(A); ----- Thread M: lock_acquire(b) ------------------
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |    M     |    H     |-
---------|pri: L->pri|pri: M->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[]  |locks:[]  |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:0 |blocker:0 |-
--------------------------------------------------------------------------------
-thread_get_priority(L)=1 - thread_get_priority(M)=2 - thread_get_priority(H)=3-
================================================================================
-- Thread M: lock_acquire(a) ---------------------------------------------------
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |    H     |-
---------|pri: M->pri|pri: M->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[A] |locks:[]  |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:0 |-
--------------------------------------------------------------------------------
-thread_get_priority(L)=2 - thread_get_priority(M)=2 - thread_get_priority(H)=3-
================================================================================
-- Thread H: lock_acquire(b) ---------------------------------------------------
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |H-blocked |-
---------|pri: H->pri|pri: H->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[A] |locks:[B] |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:&M|-
--------------------------------------------------------------------------------
-thread_get_priority(L)=3 - thread_get_priority(M)=3 - thread_get_priority(H)=3-
================================================================================
-- Thread L: lock_release(a) -- about to unblock Thread M: lock_acquire(a) -----
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |H-blocked |-
---------|pri: NULL  |pri: H->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder:NULL|holder: M  |-----------|locks:[]  |locks:[B] |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:&M|-
--------------------------------------------------------------------------------
-thread_get_priority(L)=3 - thread_get_priority(M)=3 - thread_get_priority(H)=3-
================================================================================
-- Thread M: lock_acquire(a) completes -----------------------------------------
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |    M     |H-blocked |-
---------|pri: M->pri|pri: H->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: M  |holder: M  |-----------|locks:[]  |locks:[B] |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:0 |blocker:&M|-
--------------------------------------------------------------------------------
-thread_get_priority(L)=1 - thread_get_priority(M)=3 - thread_get_priority(H)=3-
================================================================================
--And so on and so forth -------------------------------------------------------
\end{verbatim}

\subsection{Algorithms}
\subsubsection{B3}
The waiters list for a semaphore is ordered by descending priority. When choosing a new thread to run, the first thread in the list is picked. Thus the highest priority thread wakes first.
\subsubsection{B4}
Consider the case where there is a data structure as below:

\begin{verbatim}
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |    H     |-
---------|pri: M->pri|pri: M->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[A] |locks:[]  |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:0 |-
--------------------------------------------------------------------------------
-thread_get_priority(L)=2 - thread_get_priority(M)=2 - thread_get_priority(H)=3-
\end{verbatim}

Should High priority thread (H) call lock\_acquire(B), which is held by thread M, the sequence of events is such:
\begin{verbatim}
  (1) lock_available(B) returns false
  (2) The priorities of Thread M and thread H are compared
  (3) Since the priority of thread H is greater the priority of thread M
    (4) lock B's priority pointer is set to point to thread H
    (5) Since lock B hasn't been donated to thread M before:
      (6) lock B is donated to thread M (Function call) -->.
        (7) lock B is inserted into thread M's lock_list
        (8) Since thread M is blocked, and the blocker has lower priority than
        |   lock B's priority pointer
        | (9) Thread M's blocker's priority pointer is updated to lock B's 
        |     priority pointer.
        â””---(Recursion Step on M = M->blocker->holder)
\end{verbatim}

At the end of this logical sequence, the data structure would be so:

\begin{verbatim}
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |H-blocked |-
---------|pri: H->pri|pri: H->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[A] |locks:[B] |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:&M|-
--------------------------------------------------------------------------------
-thread_get_priority(L)=3 - thread_get_priority(M)=3 - thread_get_priority(H)=3-
\end{verbatim}

Nested donation is handled via the recursive step.

\subsubsection{B5}

Considering the case where data structure is as such:

\begin{verbatim}
--------------------------------------------------------------------------------
- Locks: |     A     |     B     |- Threads: |    L     |M-blocked |H-blocked |-
---------|pri: H->pri|pri: H->pri|-----------|pri: 1    |pri: 2    |pri: 3    |-
---------|holder: L  |holder: M  |-----------|locks:[A] |locks:[B] |locks:[]  |-
---------------------------------------------|blocker:0 |blocker:&L|blocker:&M|-
--------------------------------------------------------------------------------
-thread_get_priority(L)=3 - thread_get_priority(M)=3 - thread_get_priority(H)=3-
\end{verbatim}

Should lock\_release(A), be called by Thread L:
\begin{verbatim}
 (1) Since A's priority has been been donated to L
    (2) thread_restore_priority_lock(A) is called
      (3) list_remove(A->elem) is called to remove A from L's lock_list
  (4) The lock's priority is set to NULL
  (5) The lock's holder is set to NULL
  (6) sema_up(A->semaphore) is called
    (7)  The list of waiters is ensured sorted by descending priority
    (8)  The top priority waiter is popped off the list
    (9)  This waiter is unblocked
\end{verbatim}

\section{Advanced Scheduler}
\subsection{Data Structures}
\subsubsection{C1}

Added to \tx{struct thread}: \\
\tab\tab \tx{int recent\_cpu;} \\
\tab\tab An exponentially weighted moving average of the CPU time received by each thread.
\\\\
Added to \tx{thread.c}: \\
\tab\tab \tx{\#define MLFQS\_RECOMPUTE\_INTERVAL 4} \\
\tab\tab Amount of clock ticks after which the priorities of the threads will be recomputed.
\\\\
\tab\tab \tx{static struct list thread\_mlfqs\_queue}\\
\tab\tab Queue of the ready to run threads used by the mlfqs scheduler.
\\\\
\tab\tab \tx{static long long mlfqs\_recompute\_ticks} \\
\tab\tab Number of ticks until the thread priorities will be recomputed.
\\\\
\tab\tab \tx{static int mlfqs\_load\_avg}\\
\tab\tab The system's load average, an estimate of the number of threads ready to be run in the \\
\tab\tab past minute.
\newpage
\subsubsection{C2}
\begin{verbatim}
timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59      A
 4      4   0   0  62  61  59      A  
 8      8   0   0  61  61  59      B
12      8   4   0  61  60  59      A
16      12  4   0  60  60  59      B
20      12  8   0  60  59  59      A     
24      16  8   0  59  59  59      C
28      16  8   4  59  59  58      B 
32      16  12  4  59  58  58      A        
36      20  12  4  58  58  58      C
\end{verbatim}

\subsubsection{C3}
The only possible ambiguity is the choice of which thread to run when two or more threads have the same priority. However, the specification says that if there is more than one thread with the same priority, the scheduler must go through them following a round-robin order. In our implementation, when a thread yields, it is put back into the list of ready threads, and we took care of inserting after all the threads with the same priority.

\subsubsection{C4}
Our initial fixed-point implementation consisted of a struct containing a number used for the fixed-point number representation, and several functions to perform the necessary fixed-point operations using this struct. Even if the implementation was correct, we deemed it inefficient: calling a function to perform simple mathematical operations was a significant overhead, especially considering that the kernel needs to recompute the priority of all the threads every second. In the end, we created a \tx{fixed\_point} typedef to an \tx{int32\_t}, and then defined a series of inline functions which actually implement the methods needed to perform the fixed-point operations. We chose inline functions over macros because inline functions are more practical when dealing with adding assertions.

\subsubsection{C5}

\subsubsection{C6}

At the beginning, the fixed-point representation was implemented storing the actual value of the number in a struct, and using several functions to  perform the necessary operations. Even if the implementation was correct, it was judged not efficient by the members of the group: having to call a function only to perform a mathematic operation was cause of a huge time loss, especially considering that each second, the kernel needs to recompute the priority of each thread. Moreover, the memory usage due to representing the number with a struct could be easily avoided. In the end, we decided to define \texttt{fixed\_point} as a typedef of an \texttt{int32\_t}, and then define a series of inline functions to actually implement the methods needed to perform the operations. This strategy was preferred to implementing macros because inline functions are more practical when dealing with adding assertions or bits of codes.

\end{document}