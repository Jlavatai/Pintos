\documentclass[a4wide, 11pt]{article}
\usepackage{a4, fullpage}
\usepackage[margin=2.5cm]{geometry}
\setlength{\parskip}{0.4cm}
\setlength{\parindent}{0cm}
\newcommand{\tx}{\texttt}

\begin{document}
\title{Pintos Task 3 : Virtual Memory}
\author{Francesco Di Mauro, Thomas Rooney, Alex Rozanski}

\maketitle

\section{Page Table Management}
\subsection{Data structures - A1}
\subsubsection{Data referring to the Supplemental Page Table}

Added to \tx{struct thread} in \tx{thread.h}:
\begin{verbatim}
struct hash supplemental_page_table;
struct lock supplemental_page_table_lock;
\end{verbatim}
Hash table representing the supplemental page table, and lock used to make supplemental page table modifications atomical. \\\\
Added to new file \tx{page.h}:
\begin{verbatim}
enum page_status {
   PAGE_UNDEFINED = 0,           /*default status*/
   PAGE_FILESYS = 1 << 0,        /*page referring to a file*/
   PAGE_SWAP  = 1 << 1,          /*page in the swap partition*/
   PAGE_MEMORY_MAPPED  = 1 << 2, /*page representing a mem mapd file*/
   PAGE_IN_MEMORY = 1 << 3,      /*page currently stored in memory*/
   PAGE_ZERO = 1 << 4,           /*page of zero bytes*/
};
\end{verbatim}
Enum used to represent the status of a page in the supplemental page table.

\begin{verbatim}
struct page_filesys_info {
   struct file *file;
   size_t offset;
};
\end{verbatim}
If a page refers to a file in the file system, this struct will store information regarding the actual file in memory.


\begin{verbatim}
struct page {
   struct hash_elem hash_elem;   	/* Used to store the frame in the page table. */
   void *vaddr;                   /* The address of the page in user virtual memory. */
   void *aux;	               					    /* A pointer to auxiliary data */
   enum page_status page_status;  /* Used to store the page's current status. */
   bool writable;					                /* Stores if a page is writable or not */
};
\end{verbatim}
Struct holding information about a page stored in the supplemental page table.

\subsubsection{Data referring to the Frame Table}

Added to the new file \tx{frame.h}:
\begin{verbatim}
struct hash frame\_table;
\end{verbatim}
System wide hash table representing the Frame Table.

\begin{verbatim}
struct frame {
   struct hash_elem hash_elem;		   /* Used to store the frame in the frame table. */
   int32_t frame_addr;				           /* The address of the frame in memory.*/
   struct page *page;				            /* Stores the page mapped into this frame*/
   tid_t owner_id;						               /* Stores the tid of the owning thread*/
   int32_t unused_count;          /*Represents how many times the frame was not evicted*/
};
\end{verbatim}

Added to the new file \tx{frame.c} 
\begin{verbatim}
struct lock frame_table_lock;
struct lock frame_allocation_lock;
\end{verbatim}
These locks are used to avoid concurrent modification to the frame table, and to avid concurrent access to the frame allocation process.



\subsection{Algorithms}
\subsubsection{A2}
The location of a frame is handled mainly via the supplemental page table.
When an executable is loaded, the new function \tx{load\_executable\_page()} is called. This function will take care of analysing the content of the segment that should be loaded, and instead of bringing it directly into memory (thus allocating a frame), it will add a mapping in the supplemental page table. This is carried out by initialising a \tx{struct page}, storing the virtual address of the page to be mapped and setting the field \tx{page\_status} to one (or more) of the statuses in the \tx{enum page\_status}, depending on the nature of the segment. \\
Upon page fault, the supplemental page table is consulted: if an entry is not present, we decide whether it is a memory access that requires a stack growth, otherwise the memory access is invalid. But if an entry is found, then, at first, the function \tx{frame\_allocator\_get\_user\_page()} is called. This function will, in turn
\begin{itemize}
\item Call \tx{palloc\_get\_page()}, which will retrieve a frame from the user pool, possibly evicting a frame already in memory;
\item Add a page table entry for this page - frame mapping in the page table;
\item Return the page's address.
\end{itemize}
The additional work that \tx{frame\_allocator\_get\_user\_page()} carries out is to create a \tx{struct frame}, recording the address of the allocated frame, the address of the page  mapped, the \tx{tid\_t} of the thread owning the frame, and then adding this struct to the frame table. The frame will then be filled with the correct information: it will be zeroed, or the content of a file in the file system will be copied. \\
Before returning from the page fault handler, the page will me marked as present in memory in the supplemental page table.

\subsubsection{A3}

In our design, we do not need to access the flags for if a page is dirty or accessed except for in the page eviction algorithm. In the page eviction algorithm, we have access to the user virtual addresses so can look up the accessed/dirty bits in the page directory, and thus we have no need to store the dirty and accessed bits inside the frame table entry.

\subsection{Synchronization}
\subsubsection{A4}
The initial implementation of synchronisation for frame allocation comprised of a lock around any access to the frame table in the two functions \tx{frame\_map} and \tx{frame\_unmap}. These function are responsible for adding and removing mapping in the frame table, and are the only ones which have direct access to it. \\
However, while implementing eviction, we noted that this form of synchronisation, which dealt only with concurrent access to the frame table, was not enough in order to prevent races. More specifically, since the frame table modification is the one of the last steps in the algorithm for eviction, the need to prevent threads from trying to request frames during eviction arose. Therefore, the whole action of requesting and allocating a frame is now atomical.
\subsection{Rationale}
\subsubsection{A5}
When dealing with data storage using data structures in Pintos, the use of a hash table was almost an immediate choice for us. Using a hash table both for the supplemental page table and the frame table allows us to perform insertion, deletion and lookups very easily, while also being a memory efficient solution. Early designs included a bitmap in addition to the frame table, used in order to perform look-ups even faster, and to choose a frame for eviction very efficiently. However, in the end the we abandoned the idea because, despite having some advantages, the frame unmapping operations became time consuming, since two data structures needed modification in order to represent the fact that a frame was not mapped any more.

Another important advantage of a hash table, compared to a linked  list, is that resource reclamation upon process exit was very trivial to implement. Hash tables, in fact, provide a method for destruction which take as a parameter a function pointer: this function is called onto every  element present in the table when freeing it. Exploiting this feature in the supplemental page table destruction, choosing a course of action for each specific page status was trivial: the \tx{supplemental\_page\_table\_destroy\_func}, for example, will remove from the frame table all the frames that the exiting thread held in memory.

\section{Paging to and from disk}

\subsection{Data structures}
\subsubsection{B1}

Added to new file \tx{swap.h}:
\begin{verbatim}
/* Stores if a block is in use or not, and the location of that block */
struct swap_entry {
   block_sector_t block;
   bool in_use;
};
\end{verbatim}

Added to new file \tx{swap.c}:
\begin{verbatim}
/* The number of sectors in a page. */
#define PAGE_NUM_SECTORS PGSIZE / BLOCK_SECTOR_SIZE 

/* Swap Block Pointer - points to the block dedicated to swap on the filesystem */
static struct block *swap_block; 

/* Size of the Swap Block in bytes */
static size_t swap_size;

/* Number of pages that will fit into the Swap block */
static size_t max_pages;         

/* Global lock to stop concurrent access of the swap table. */
static struct lock swap_lock;        

/* The Swap Table Array */
static struct swap_entry *swap_table;

/* The Size of the Swap Table in bytes */
static size_t swap_table_size;
\end{verbatim}


\subsection{Algorithms}
\subsubsection{B2}
The choice of a suitable frame to evict is implemented via a Least Recently Used based algorithm.\\

\begin{itemize}
\item We traverse the list of all the frames, maintaining four variables: the \tx{eviction\_candidate}; the \tx{least\_used} value of the eviction candidate, a \tx{dirty\_candidate} flag and a \tx{accessed\_candidate} flag.

\item As we traverse the list of frames, we check if the page is accessed, or dirty. If so, and we have a candidate that is not $<$dirty or accessed$>$, we don't consider it as a candidate. This is due to a non-dirty candidate not requring a write to the file system, it can simply be free'd.

\item If it's still a candidate, we then increment the \tx{unused\_count} variable, and compare it against the candidate's \tx{unused\_count} value. If it is greater, i.e. it's been unused for longer, then that becomes the candidate.
\end{itemize}

The end result of this algorithm, is that we evict the oldest, non-dirty and non-accessed page. If there are none, we instead evict the oldest non-accessed and dirty or non-dirty and accessed page. If there are yet none of them, we evict the oldest page.

\subsubsection{B3}

When process $P$ needs to evict a new frame in its call for \tx{frame\_allocator\_free\_user\_page()}, and it chooses a page from process $Q$, we look at the page from process $Q$ to decide where it should be placed when evicted, if anywhere.

\begin{itemize}
\item If the frame is a non-dirty filesystem frame, then it can just be \tx{free()}'d, and the supplemental page table updated to represent the fact that it is no longer in memory (via the page's \tx{page\_status} member). When it page faults again, it will simply be loaded once more from its original location.
\item If the frame is a non-dirty memory-mapped frame, once again we just free it and declare the corresponding page as no longer in memory (via the page's \tx{page\_status}), so we can load it again where necessary.
\item If the frame is dirty and non-stack, we write it back to its original location, and declare it as no longer in memory via \tx{page\_status}. We then free the frame.
\item Otherwise, we write the frame to swap, and declare it as in swap so it can be loaded when there is a page fault. We then free the frame.
\end{itemize}

After the frame has been \tx{free()}'d, process $P$ can allocate the frame, and because the allocation function is atomic (using a lock) it is ensured that it will get the just-evicted frame of memory.

\subsection{B4}

To decide if a virtual address is invalid, or need's the stack to grow, we pass it through this function:
\begin{verbatim}
-- In exception.h
/* Maximum Stack Size: 8 megabytes*/
#define MAX_STACK_SIZE 8388608

-- In exception.c
bool
is_in_vstack(void *ptr, uint32_t *esp)
{
  return  ((PHYS_BASE - pg_round_down (ptr)) <= MAX_STACK_SIZE
           && (uint32_t*)ptr >= (esp - 32));
}
\end{verbatim}

We consider a pointer to be in the ``virtual stack'', when it is between the bottom of the stack and the bottom minus the maximum stack size (8MB). This is done by first checking if the difference between \tx{PHYS\_BASE} and the pointer's page directory, is less than (or equal to) this maximum stack size.

We also consider that the given pointer is greater than 32 bytes lower than esp. This is because the furthest page fault from esp which requires page growth, is that which is caused by the assembly \tx{PUSHA} instruction. This can be seen in the test \tx{pt-grow-pusha}

\begin{verbatim}
     "pushal;"                   /* Push 32 bytes on stack at once. */
\end{verbatim}

\subsection{Synchronization}
\subsubsection{B5}

The Frame Table and the Swap Table are global data structures, which is why we use global locks to control and synchronise access. Since these resources are shared between all threads, it becomes critical to prevent different thread to interfere with operations regarding frame allocation and read and write operations concerning the swap partition.

Implementing synchronised access for the supplemental page table required more thought. The supplemental page table is only accessed by the given process, mainly when loading the executable, where the \tx{struct page} are added and the \tx{page\_status} field is set, and in the page fault handler when the page in marked as in memory. However it is also referred to when a frame belonging to a process is evicted, because the references to where the evicted frame is now located needs to be updated.

Because of this, a lock was added to each thread to lock the supplemental page table on a per-process basis. Every time the supplemental page table or any of its elements, for a given thread, is accessed or modified, we acquire this lock, ensuring that we avoid synchronisation issues, for example half-written data.

In relation to the 5 conditions causing deadlocks, here is how we have managed them:
\begin{itemize}
\item \textbf{Mutual exclusion} : there is no resource exclusively associated to a specific process, and all of them are either global or accessible from outer processes.
\item \textbf{Hold and Wait} : The various locks can be accessed only in our carefully designed order, where there are no cases where a process could acquire a lock while waiting for another to be released.
\item \textbf{No pre-emption} : Pintos locks do not implement pre-emption. This is because we are writing a kernel, and a failure in a critical section cannot be recovered from, because the state of the kernel would be uncertain. Since we lock at the beginning and end of all critical sections, and carefully designed the synchronisation, we should not get into such problems.
\item \textbf{Circular waiting}: There is no such situation in our design.
\end{itemize}

\subsubsection{B6}

This case is handled via the global frame allocation lock. When a process faults, we allocate a frame for the virtual address which faulted, and move the data stored in its previous location to this new physical address.

During this allocation, we evict a page if necessary. Because the allocation is locked down such that it's an atomic operation, if thread $Q$ is woken and immediately page fault's on the evicted address, before the allocation is finished, it will wait on the frame allocation lock. When the frame allocation is finished, frame $Q$ can continue and potentially evict another page if needed.

There is also a lock for each thread's supplemental page table. If a page is being accessed, this lock is acquired ensuring that any other accesses/writes are finished before an access is performed.

\subsubsection{B7}

Any modifications to the frame table are locked globally to ensure atomicity. If process $P$ requires a new frame (to handle a page fault), it will acquire this lock. Once it is acquired, a second process $Q$ can not modify the frame table in any way until it's completed, by the use of this global lock.

Also, once a page is read in, it will have an \tx{unused\_count} of 0. When we choose to evict a page, we choose the highest \tx{unused\_count}, where \tx{unused\_count} is both affected by age and how often it is accessed and written to. Thus if a page is recently read in, it is (very) unlikely to be evicted any time soon.

\subsubsection{B8}
Paged out pages which need to be brought in memory need a special treatment when dealing with system calls, and, most importantly, the \tx{read} system call. This is because the actual action of reading into the a user specified buffer could cause a page fault which could not be properly handled.

Consider the case where a thread tries to read from a buffer referring to a file, in a page referring to a file, which is not present in memory: in this case, the thread would be in the filesys critical region, and during page fault, it would try to acquire the lock again to correctly read data from the file. In order to avoid this problem, a different strategy has been implemented: The provided buffer is still validated before reading but, if it is going to page fault because the stack needs to grow to allow space for the data, the stack growth is carried out before the reading. This way, we avoid having to deal with the page fault that could potentially occur while reading.  

\subsection{Rationale}
\subsubsection{B9}

Our Design has:
\begin{itemize}
\item 1 Global lock for modifications to the Frame Table \tx{struct}.
\item 1 Global lock for the Frame Allocation/Free/Eviction.
\item 1 Global lock for the Swap Table.
\item 1 Per Process lock for the Supplemental Page Table.
\end{itemize}

The lowest level of parallelism is to have one global lock for the entirety of the \tx{VM} Module. We chose to not do this because it limits parallelism very significantly, and it does not require significantly greater complexity for a per-module lock.

We originally intended to have a seperate lock for each frame table entry and swap table entry. However we decided against doing this for two reasons. We wanted to keep the design simple until all the functionality was correct, and the locking mechanisms were only one small portion of the designs.

The design we chose makes a good tradeoff between high parallelism and the amount of time available for the task. We believed, as a team, that getting a functional design was of much more value then a highly parallel, flawed design. It is easier to work from a base standard of behaviour to a faster implementation of that same behaviour, than it is to implement the more optimal version first.

We didn't want to prematurely optimise our code (the root of all evil), especially from what we've learnt from the previous Pintos tasks. We believe that we have a design that is parallelisable, and are happy with it.

\section{Memory Mapped Files}
\subsection{Data structures}
\subsubsection{C1}
Added to new file \tx{page.h}:

This struct stores information about a page-worth of data for a memory-mapped file, and is associated with a memory-mapped page in the supplemental page table.
\begin{verbatim}
struct page_mmap_info {
    mapid_t mapid;                  /* The mmap() mapid. */
    size_t offset;                  /* The offset into the file. */
    size_t length;                  /* The number of bytes of the file stored
                                       in this page. */
};
\end{verbatim}

Added to new file \tx{mmap.h}:
\begin{verbatim}
typedef int mapid_t;
#define MMAP_MIN_MAPID       0      /* The lowest valid mmap id. */
#define MMAP_ERROR_MAPID     -1     /* Denotes a mmap error. */
\end{verbatim}

This struct stores information about each memory mapped file in the process's memory-map table.
\begin{verbatim}
struct mmap_mapping
{
    struct hash_elem hash_elem;     /* Used to store the struct in the hash table. */
    mapid_t mapid;                  /* The memory map identifier. */
    struct file *file;              /* The file being mapped into memory. */
    void *uaddr;                    /* The user virtual address that the
                                       file is mapped from. */
};
\end{verbatim}

\subsection{Algorithms}
\subsubsection{C2}

When a file is memory-mapped, we first determine how many pages worth of memory would be used by the file. We then add an entry to the supplemental page table for every page (starting from the user virtual address that the file is to be mapped from).

The information about each page that is added to the supplemental page table is stored in a \tx{struct page}. For each memory-mapped page that we add to the supplemental page table, we allocate a \tx{page\_mmap\_info} struct. This contains members for the map ID (which is the value returned by \tx{mmap()}), the offset into the file that's being memory mapped to the page, and the length of memory-mapped file from the offset that this page contains (this will likely be \tx{PGSIZE} but will be less for the last page of the memory-mapped file if the file is not a multiple of \tx{PGSIZE}).

We then set the \tx{aux} member of the \tx{struct page} to point to this new \tx{struct page\_mmap\_info}, and the \tx{page\_status} to be \tx{PAGE\_MEMORY\_MAPPED} to denote that this is a page for a memory-mapped file.

The page faulting process for a memory-mapped file page is similar to that for an executable page in that we load data from the filesystem into the frame allocated for the page of memory. However, when we load in a page-worth of memory-mapped file, we have to look up the memory mapping in the thread's memory map table (the \tx{mmap\_table} member of \tx{struct thread}). From this, we can get the \tx{struct file} pointer for the file that has been mapped into the user virtual address space, and then read the chunk of data from disk. This is different to how we deal with executable pages, as each \tx{struct page}'s \tx{aux} member points to a \tx{struct page\_filesys\_info} which contains the underlying \tx{struct file} pointer directly. Since we want to be able to access the memory-map info via the memory map ID for each memory-mapped page, we only store this ID and not the \tx{struct file} pointer directly in \tx{struct page\_mmap\_info}. Storing the file pointer in each \tx{struct page\_mmap\_info} as well as in the \tx{struct mmap\_mapping} would be unnecessary duplication and could lead to more bugs because of data inconsistency (if the file pointer wasn't set in one struct, for instance).

\subsubsection{C3}

The \tx{mmap()} system call is called with the user virtual address that the file should be mapped from in memory. In \tx{mmap\_handler()} in \tx{syscall.c} (which implements the behaviour for \tx{mmap()}) we first determine the number of pages that the memory-mapped file will span over. Since every page used by the user program has a corresponding entry in the supplemental page table, we iterate over every starting page address for the memory-mapped file starting from the address the file should be mapped from.

For each of these addresses, we check the supplemental page table for whether a page is already in use at this user virtual address. If a page entry exists in the supplemental page table for any of these addresses, it denotes that the memory-mapped file would overwrite an existing memory segment, and so we return \tx{-1} to indicate that the memory-mapping failed.

\subsection{Rationale}
\subsubsection{C4}

We do not share much of the code for the two situations, because even though their implementations are both shared in that they demand-page their data from disk and write their data back to disk on eviction, we have abstracted how we handle memory-mapped file pages and executable pages in different ways, such that it wouldn't make sense to share much of their implementation. Trying to mould both to use the same system would just add complexity to the code, whilst not gaining much: the code to read and write data to the filesystem consists of only a few filesystem calls.

\end{document}
