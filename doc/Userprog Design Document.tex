\documentclass[a4wide, 11pt]{article}
\usepackage{a4, fullpage}
\newcommand{\tab}{\hspace*{2em}}
\usepackage[margin=2cm]{geometry}
\newcommand{\tx}{\texttt}

\begin{document}

\title{OS 211 \\ Task2: User Programs \\ Design Document}
\author{Francesco Di Mauro, Thomas Rooney, Alex Rozanski}
\date{\today}
\maketitle

\section{Argument Passing}
\subsection{Data Structures}
\subsubsection{A1}
Added to \tx{process.c}:
\tab \begin{verbatim}
     struct argument
     {
         char *token;
         struct list_elem token_list_elem;
     };
\end{verbatim}
\tab The struct represent an argument, which \tx{char *token} is pointing to. This struct can be added to a list struct.
\\
\tab \begin{verbatim}
     struct stack_setup_data
     {
         struct list argv;
         int argc;
     };
\end{verbatim}
This struct stores the data needed to setup the stack in \tx{start\_process}, namely a list of \tx{struct argument} and the number of arguments. 

\subsection{Algorithms}
\subsubsection{A2}
Argument parsing is divided between the functions \tx{process\_execute} and \tx{start\_process}. \\\\
At the beginning of \tx{process\_execute}, a fresh memory page is allocated and zeroed: this page will store the setup data information. A copy of the pointer to this page, \tx{thread\_page\_ptr}, will be increased every time of the required amount, in order to properly store the information needed without corrupting memory. Afterwards, the file name passed as an argument to the Pintos command is tokenized, the pointer to each token is stored into a \tx{struct argument}, and then added to the \tx{argv} list. Each struct is pushed at the front of the list, so that at the end the arguments will already be in reverse order, as needed. \\\\
The function \tx{start\_process}, takes care of pushing the arguments onto the stack. Firstly, it saves the pointer to the name of the process, which will be needed in order to free the \tx{fn\_copy} memory page, where the file name and arguments are stored, at the end of the stack setup. Then, after setting up the interrupt frame, the function iterates over the list of arguments a first time: in this first ``pass'', the string value of each argument will be copied onto the stack, modifying the location that the \tx{esp} is pointing to depending on the length of the string. The iteration will be from the front to the end of the list, since the arguments are already in reverse order. Moreover, the \tx{char} pointers pointing to the arguments in the \tx{fn\_copy} memory page, will be substituted with their corresponding pointers on the stack (the address the \tx{esp} is pointing to). The function will then push an all-zero (\tx{NULL}) byte as a word alignment, and a \tx{NULL} pointer, in order to respect the convention that \tx{argv[argc] = NULL}. Afterwards, the function will iterate over the same list again, this time pushing the pointers to the strings in the same (reverse) order. Finally, the pointer to the first argument will be pushed, followed by \tx{argc} and the ``fake'' return address. Before returning, the fuction will free both the allocated memory pages. \\\\
Overflowing the stack is avoided by checking the esp value every time it is modified: if the difference between \tx{PHYS-BASE} and the current esp is bigger than 4KB, the process stops with an error code.

\subsection{Rationale}
\subsubsection{A3}
The main difference between the functions \tx{strtok()} and \tx{strtok\_r()} is that the latter has an extra parameter, another \tx{char *}, which stores, after each tokenization, the pointer to the new location. This way, a subsequent call to the same function will tokenize the rest of the list starting from the previous address. The function \tx{strtok}, instead, stores the new location in an internal variable. Since Pintos might switch threads to run while this tokenisation is taking place, the value of this internal variable would be lost, making any further tokenisation impossible, while possibly causing illegal memory accesses.
\subsubsection{A4}
A disadvantage of the Pintos method is that, before the tokenisation, the command passed is copied into a memory page to avoid race conditions. This imposes a 4KB limit on the command line, which is not present in UNIX. \\\\
Moreover, if something goes wrong  in the argument parsing in Pintos, the whole kernel would panic and interrupt the execution. Parsing the arguments at a higher stage allows to identify errors before they make the whole kernel crash.\\\\
By argument parsing in a terminal, Unix can perform more parsing of command strings by preprocessing it before it sends information to the kernel. This allows for more advanced manipulation of process execution, with features such a semicolon (`;') allowing multiple commands in a single line, and piping.

\section{System Calls}
\subsection{Data Structures}
\subsubsection{B1}

Added to \tx{syscall.c}:

\begin{verbatim}
     static struct lock file_system_lock;
\end{verbatim}

\tab A lock used to ensure that only one file system operation is performed at any one time.

\begin{verbatim}
     typedef void (*SYSCALL_HANDLER)(struct intr_frame *f);
\end{verbatim}

\tab The function type used by all functions which implement the system calls.

\begin{verbatim}
     static const SYSCALL_HANDLER syscall_handlers[] = {
       &halt_handler,
       &exit_handler,
       &exec_handler,
       &wait_handler,
       &create_handler,
       &remove_handler,
       &open_handler,
       &filesize_handler,
       &read_handler,
       &write_handler,
       &seek_handler,
       &tell_handler,
       &close_handler
     };
\end{verbatim}

\tab A static array of function pointers used for system calls indexed by their respective system call number.

\begin{verbatim}
struct proc_information { 
    struct list_elem elem;                  /* To provide linked list functionality */
    pid_t pid;             /* Stores the pid (equivilent to tid) for the child process */
    int exit_status;                  /* Stores the exit_status for when the process dies */
    
    struct condition condvar_process_sync;  /* A synchronisation primitive to help synchronise 
                                                parent and child threads*/
                                                
    struct lock anchor;                     /* A lock held during the thread's life */
    bool parent_is_alive;          /* A boolean to determine if the parent thread is alive */
    bool child_is_alive;           /* A boolean to determine if the child thread is alive */
    
    bool child_started_correctly;       /* A boolean to determine if the child thread 
                                       started correctly (i.e. loaded executable etc) */
    
    struct hash file_descriptor_table;    /* Stores descriptors for files opened by 
                                            the current process. */ 
    int next_fd;                          /* Stores the next file descriptor for use. */
};
\end{verbatim}

\tab This struct stores synchronisation information between parent and child threads.

\begin{verbatim}
  struct thread
  {
    ...
    #ifdef USERPROG
      struct file * file;                  /* A pointer to the struct holding the executing 
                                              file this thread's code is contained in */
      struct proc_information * proc_info; /* A pointer to the parent's information struct
                                              containing information on this child */
      struct list children;                /* Holds the list of processes started by this
                                              process. */
      /* Owned by userprog/process.c. */
      uint32_t *pagedir;                  /* Page directory. */
  #endif
    ...
  }
\end{verbatim}

\tab This added information to \  tx{struct thread} stores information on parent and child threads to allow for synchronisation, and the location of the executing code on the file system.

\subsubsection{B2}

File descriptors are associated with open files through a hash table. Each process's thread stores a hash table which associates file descriptors with \tx{struct file\_descriptor}s. \tx{struct file\_descriptor} stores a \tx{struct file} pointer which can then be used with the file and filesystem kernel functions.
\\\\
File descriptors are unique within a single process, as there is no need for them to be unique within the entire OS since they only identify open files at the process level.

\subsection{Algorithms}
\subsubsection{B3}

Reading and writing user data from the kernel is managed by the system calls which we implemented for this task. The system call interrupt handler (\tx{syscall\_handler()}) is the entry point for all of our system calls. In this function, we first get the system call number, which is stored at the addresss pointed to by the \tx{esp} member in the interrupt frame.

We have a mapping between system call numbers and functions which we have implemented to provide the functionality for each system call. This mapping is performed through an array of function pointers, \tx{syscall\_handlers}, which is stored in \tx{syscall.c}. The pointer to the function which implements a particular system call is indexed by the system call number; for example, the \tx{exec} system call has system call number \tx{2}, so the function \tx{exec\_handler()} which implements this system call is stored at index 2 in the \tx{syscall\_handlers} array.

\subsubsection{B4}

The least number of calls to \tx{pagedir\_get\_page()} that could result would be 1, if all of the data that was being copied from user space to the kernel was stored in a single page, from address 0 within that page. The maximum number of calls to \tx{pagedir\_get\_page()} would be 4,096, if each byte that was being copied was stored in a different page.

For a call that only copies 2 bytes of data, the least number of calls to \tx{pagedir\_get\_page()} that could result would again be 1, if the 2 bytes were stored in the same page. The maximum would be 2 this time, if both bytes were stored in different pages.

We don't see much room for improvement. If we ensured that memory pages were contiguous, a 4096 bytes could be split over a maximum 2 pages of memory, requiring only two inspections. This cannot be ensured however, as fragmentation naturally occurs with the current implementation.

\subsubsection{B5}

Our implementation of the wait system call is done via a call to the kernel function \texttt{process\_wait}, with an argument of the process id (\texttt{pid}). This function looks through a linked-list of processes spawned by the calling process (that haven't been cleaned up yet), and returns -1 if it can't find the given \texttt{pid}.
\\\\
If it can find the \texttt{pid}, a check is then performed to see if the process has already finished. This is implemented by a boolean flag set to \texttt{true} by the child process when it finishes. If it has already finished, it returns the \texttt{exit\_status} that the process had when it finished. If it hasn't it performs a \texttt{cond\_wait} until the child process signals that it is finished. We avoid race conditions via a \texttt{lock}, meaning that as soon as the child's pid is found in the children's list, the operations become atomical.
\\\\
Finally, after either the \texttt{child\_is\_alive} check passes or the process is signalled, the process memory is cleaned up, and the child information struct is removed from the linked list.

\subsubsection{B6}

We have separated the different parts of the system calls cleanly into a few parts:

\begin{enumerate}
\item We have encapsulated the code which validates user memory addresses into a function in \tx{syscall.c}, \tx{validate\_user\_pointer()}. This method checks whether the pointer is valid, and if not calls \tx{exit()} with a status code of \tx{-1}. Because it simply terminates if the memory address is invalid, this means that it does not have to return a value. If execution continues beyond a call to \tx{validate\_user\_pointer()}, it means that the memory address is a valid user memory address. If it was not, then \tx{exit()} would have been called, taking care of freeing all the process's resources, and execution of the user program would not have continued.
\item \tx{syscall\_handler()} is the entry point for all of our system calls; at this point we first validate \tx{esp} before dereferencing it using \tx{validate\_user\_pointer()}. As mentioned in 1), this is only a single function call, with no return value. After this, we invoke the correct system call handler function (by looking at the correct element in \tx{syscall\_handlers}). This single call to \tx{validate\_user\_pointer()} is the only user memory address validation we do in this function.
\item For each system call handler function, we retrieve the arguments on the stack by calling \tx{get\_stack\_argument()}, which takes two arguments: the interrupt frame for the system call and the argument index. This function evaluates the address which this argument should be stored at (based on the \tx{esp} value stored in the interrupt frame), then calls \tx{validate\_user\_pointer()} with this address, then returns the dereferenced value at that address. The fact that argument retrieval is handled in another function means that the system call functions are very clean, and do not contain a swathe of address checking or error handling code. Any pointer arguments which then also require validation can be checked in the system call handler with \tx{validate\_user\_pointer()}.
\end{enumerate}

For example, the code in the \tx{write} system call handler which validates the stack arguments is very minimal:

\begin{verbatim}
// From write_handler() in syscall.c.
int fd = (int)get_stack_argument (f, 0);
const void *buffer = (const void*)get_stack_argument (f, 1);
unsigned size = (unsigned)get_stack_argument (f, 2);

validate_user_pointer (buffer);

// Code to implement the write system call.
// ...
\end{verbatim}

\subsection{Synchronisation}
\subsubsection{B7}

The \tx{exec} system call, in our implementation calls \tx{process\_execute}, alike a kernel call to start a new process. In \tx{process\_execute}, we allocate a heap memory structure for a shared memory structure between parent and children threads. This memory structure has pointers from both parent and child thread structs. It contains a few boolean flags for specific situations, an \tx{exit\_status}, a lock (called anchor) and condition variable. The \tx{exit\_status} is initialised to \tx{0xdeadbeef}.
\\\\
After the \tx{thread\_create} function has been called by the parent thread, the parent thread acquires the shared lock \tx{anchor}, and checks to see if the \tx{exit\_status} is still \tx{0xdeadbeef}. If so, it calls \tx{cond\_wait}, to be signalled when the created thread has started correctly.
\\\\
After \texttt{load} is called by the child thread, the lock is acquired. The \tx{exit\_status} is set to \tx{-1} (so an unexpected interrupt returns exit status \tx{-1}). Furthermore a boolean flag is set to tell the parent process if the child process started correctly or not. If it didn't, the parent process returns \tx{-1} from the \texttt{exec} system call. Else it returns the tid. The parent is finally signalled by the condition variable and the lock released.

In code:

\begin{verbatim}
... process_execute (process.c) ...
    lock_acquire(&proc_info->anchor);
    if (proc_info->exit_status == (int)UNINITIALISED_EXIT_STATUS) // 0xdeadbeef
      cond_wait(&proc_info->condvar_process_sync, &proc_info->anchor);
    if (!proc_info->child_started_correctly)
      tid = EXCEPTION_EXIT_STATUS;
    lock_release(&proc_info->anchor);
...
\end{verbatim}

\begin{verbatim}
... start_process (process.c) ...
  lock_acquire(&cur->proc_info->anchor);
  cur->proc_info->exit_status = EXCEPTION_EXIT_STATUS; // -1
  cur->proc_info->child_started_correctly = success;
  cond_signal(&cur->proc_info->condvar_process_syncs, &cur->proc_info->anchor);
  lock_release(&cur->proc_info->anchor);
...
\end{verbatim}

\subsubsection{B8}

To handle all three cases, in our process syncronisation shared memory structure, we have two boolean flags:

\begin{verbatim}
    bool parent_is_alive;          /* A boolean to determine if the parent thread is alive */
    bool child_is_alive;           /* A boolean to determine if the child thread is alive */
\end{verbatim}

During \tx{process\_exit}, the relevant flag for the process which is exiting is set to false. I.e.: in their child's \tx{proc\_information} struct, the \tx{parent\_is\_alive} flag is set to false, and in the one shared with their parent, should there be one, the \tx{child\_is\_alive} flag is set to false.

Then, if and only if both of these are set to false, the shared memory structure is cleaned up. The logic is also within the shared memory structure's lock such that the logical checks are atomic.

In \tx{process\_wait}, we wait for the child via a check on it's boolean condition \texttt{child\_is\_alive}, and a \texttt{cond\_wait} if true. After this, we save it's \texttt{exit\_status} variable, remove references to the shared memory struct, and cleanup the memory.
\\\\
This has the side benefit of returning \tx{-1} as required the next time we call \texttt{process\_wait} on the same process pid, as the child's pid is no longer a member of the process's children process list.
\\\\
Thus all cases are covered and cause memory to be cleaned up correctly. For a walkthrough of logic in the major cases see below:- P represents the \texttt{parent} process and C the \texttt{child}.

\begin{enumerate}
\item P calls wait(C) before C exits - wait calls \texttt{cond\_wait}; C calls \texttt{process\_exit}; C checks P is still alive and signals it, then exits without cleanup; P resumes executing and cleans up memory and returns the \texttt{exit\_status} from wait(C).
\item P calls wait(C) after C exits - when C exits, it sees P is still alive and exits without shared memory cleanup; when P calls wait(C), it sees C is not alive and cleans up the shared memory, returning the \texttt{exit\_status}.
\item P terminates without waiting, after C - when C exits, it sees P is still alive and exits without shared memory cleanup; when P exits it sees that C is dead and the allocated memory is still there, so it cleans it up.
\item P terminates without waiting, before C - when P exits, it sees that C is still alive and exit's without shared memory cleanup; when C exits, it sees P is not alive and cleans up the memory.
\end{enumerate}


\subsection{Rationale}
\subsubsection{B9}

We chose to implement access to user memory in the way we did because it allowed our system call implementations to easily validate accesses to user memory in only one function call. Because we exit (using \tx{thread\_exit()} if the memory access is invalid, this also means that the function does not have to return a value, because returning to the function implementing the function call from \tx{validate\_user\_pointer()} means that the memory access was valid. This means that the calling code is a lot cleaner, and doesn't have to use conditionals. The fact we call \tx{thread\_exit()} on a bad memory access means that we can also perform any cleanup operations before terminating that we'd want to do when exiting a thread normally anyway (such as ensuring that the user program isn't still holding the filesystem lock).

\subsubsection{B10}

As we use a hash table, our implementation of file descriptors is very efficient for lookup (the hash function is just the identity function). It is also space efficient, as it is a dynamically sized data structure which automatically optimises for space efficiency. As each process has its own hash table storing \tx{struct file}s which are open for that process, closing open files when the process exits is very easy (we just destroy the hash table, clearing out the contents and closing the open files).
\\
However, the fact that each process has a hash table containing open files for that process uses more memory than if we only used a single hash table which was shared between all processes.\\
Moreover, consider the case where two processes were to communicate using a file. In this case, the need for a shared file descriptor table would arise, since at this point there is no way for two processes to identify the same file using the same file descriptor. 

\subsubsection{B11}
The identity mapping between \tx{pid\_t} and \tx{tid\_t} in Pintos is a viable solution since the kernel does support only single-threaded processes. Moreover, it becomes the only way to identify a process, since there is no \tx{struct process} used to store information about the process itself. 
\\ A possible advantage of creating a more complex mapping could be that the distinction between user processes and kernel threads would become easier, for example by reserving the first $n$ identifiers to kernel threads and mapping them to values outside those range. When dealing with a identifier would then be much easier to determine its type, and choose the appropriate actions. However, one would have to suitably allocate space for storing this information, and the process of resolving this mapping could cause time loss.  
\end{document}
